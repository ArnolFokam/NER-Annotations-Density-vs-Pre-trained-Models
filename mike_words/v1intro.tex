Natural Language Processing (NLP) is a rapidly growing field that has been applied to a wide range of tasks and domains~\citep{vaswani2017Attention,conneau2019Unsupervised}. However, much of the focus in NLP has been on high-resource languages, such as English, German, and Spanish~\citep{vaswani2017Attention,conneau2019Unsupervised,radford2018Improving,radford2019language_gpt2}. While this has led to notable advancements for these languages, low-resource languages have not received as much attention, resulting in a significant performance gap between high- and low-resource languages. This has prompted an increasing number of studies focused exclusively on low-resource languages, including the development of models~\citep{ogueji2021Small,alabi2022Multilingual} and the introduction of datasets~\citep{oyewusi2021Naijaner,adelani2021MasakhaNER,adelani2022Thousand,adelani2022Masakhaner}.

Despite this impressive progress, data remains a limiting factor for low-resourced NLP~\citep{adelani2022Thousand,adelani2022Masakhaner}. In particular, the two main problems are the availability and quality of data. First, the datasets available for low-resourced languages are often smaller than those for high-resourced languages, and for many languages, no data exists at all~\citep{martinus2019Focus,adelani2021MasakhaNER}. Secondly, the available datasets are often of questionable quality, containing invalid text or incorrect annotations~\citep{kreutzer2021Quality}, which has detrimental downstream effects on the models trained on these datasets~\citep{abdul2012Extrinsic,alabi2019Massive}.

Therefore, many existing datasets in low-resourced NLP are either small, or of low-quality. This observation has led to research that investigates the tradeoff between the amount and quality of data~\citep{gasco-etal-2012-data,alabi2019Massive,abdulmumin2022Separating,de-gibert-bonet-etal-2022-quality}. This line of work is generally useful, as it allows NLP practitioners to make informed decisions when faced with a choice of which dataset should be used to train a model. However, some works consider separate corpora, label each as either ``high'' or ``low'' quality and draw conclusions from this~\citep{alabi2019Massive}. Relatedly, other works investigate data filtering, training models that score the quality of particular portions of the dataset. This is then used to filter data, selecting only a higher-quality subset of the original data~\citep{abdulmumin2022Separating,de-gibert-bonet-etal-2022-quality}. 
While these results are useful, they often compare two different datasets, potentially from different domains, without easily-quantifiable quality and quantity tradeoffs. Likewise, the filter-based methods often use a particular learned filter, again making it hard to consistently quantify the quality of the data.

We instead take a different perspective and focus on systematically and quantifiably reducing the quality of datasets and examining the effcts on the performance of NLP models. We additionally alter the amount of data used to train our models to be able to compare the tradeoffs between quality and quantity. We do this by devising various corruption strategies, and training models on different levels of corruption.
In particular, we focus on a Named-Entity Recognition (NER) task due to its prevalence in many NLP systems and the availability of a few high-quality datasets in low-resourced languages. We fine-tune existing pre-trained language models, as this is a prevalent and high-performing approach, especially for low-resourced languages~\citep{ogueji2021Small,adelani2021MasakhaNER,alabi2022Multilingual}. 

We provide systematic evidence to support prior findings that quality of data, in general, is strongly preferred over quantity. In particular, when having a budget to label a certain number of named entities, focusing on accurately labelling fewer sentences is preferred over having more, but incorrectly labelled, data. Finally, we note that our results are consistent across eleven languages and four pre-trained models, suggesting that our observations are generally valid.
